{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TvvRIbhFRKUr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "from typing import Annotated, Any, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from pydantic import BaseModel, Field\n",
        "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UDU4GnjXS6gq"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4maZX826VDhy",
        "outputId": "649541bb-cd6f-46c8-84dc-d70d1a2d4353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'AIzaSyA4jFk1n_6Y36RqytWAMCdJFRSjMCQu-Qo'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pLaaffwzUNhL"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    google_api_key= GOOGLE_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ysP6o_btKpUs"
      },
      "outputs": [],
      "source": [
        "def load_pdf(file_path):\n",
        "  loader = PyPDFLoader(file_path)\n",
        "  documents = loader.load()\n",
        "\n",
        "  text_content = \"\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "  return text_content\n",
        "\n",
        "def deidentify_and_strip(text: str) -> str:\n",
        "    cleaned_lines = []\n",
        "    for line in text.splitlines():\n",
        "        line_stripped = line.strip()\n",
        "\n",
        "        # Skip empty lines\n",
        "        if not line_stripped:\n",
        "            continue\n",
        "\n",
        "        # Rules to DROP whole lines if they contain PHI\n",
        "        if re.search(r\"(Patient|Clinician|Participants|Supervisor?):\", line_stripped, re.IGNORECASE):\n",
        "            continue\n",
        "        if re.search(r\"DOB\\s*[:\\-]?\\s*\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}\", line_stripped):\n",
        "            continue\n",
        "        if re.search(r\"\\b\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}\\b\", line_stripped):  # Dates\n",
        "            continue\n",
        "        if re.search(r\"\\b\\d{1,2}:\\d{2}\\s?(?:AM|PM|am|pm|ᴘᴍ|ᴀᴍ)\\b\", line_stripped):  # Times\n",
        "            continue\n",
        "        if re.search(r\"Date and Time:\", line_stripped, re.IGNORECASE):\n",
        "            continue\n",
        "        if re.search(r\"(Location|Clinic|Hospital|Center|LLC|LLP|PC)\\b\", line_stripped):\n",
        "            continue\n",
        "        if re.search(r\"License\\s*[:\\-]?\\s*[A-Z]*\\s*\\d+\", line_stripped, re.IGNORECASE):\n",
        "            continue\n",
        "        if re.search(r\"http\\S+|www\\.\\S+\", line_stripped):\n",
        "            continue\n",
        "        if re.search(r\"Page\\s+\\d+\\s+of\\s+\\d+\", line_stripped, re.IGNORECASE):\n",
        "            continue  # remove \"Page 1 of 2\" style lines\n",
        "\n",
        "        # Keep everything else\n",
        "        cleaned_lines.append(line_stripped)\n",
        "\n",
        "    return \"\\n\".join(cleaned_lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "38o21s3TPBC6",
        "outputId": "9cf8d30a-0838-4029-f1f7-80a2de46bd7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Diagnosis\\nF43.21Adjustment Disorder, With depressed mood\\nCurrent Mental Status\\nOrientation: X3: Oriented to Person, Place, and Time\\nGeneral Appearance: Appropriate\\nDress: Appropriate\\nMotor Activity: Unremarkable\\nInterview Behavior: Appropriate\\nSpeech: Normal\\nMood: Euthymic\\nAffect: Congruent\\nInsight: Excellent\\nJudgment/Impulse Control: Excellent\\nMemory: Intact\\nAttention/Concentration: Good\\nThought Process: Unremarkable\\nThought Content: Appropriate\\nPerception: Unremarkable\\nFunctional Status: Intact\\nRisk Assessment\\nPatient denies all areas of risk. No contrary clinical indications present.\\nSubjective Report and Symptom Description\\nClient noted recent anxiety and tearfulness.\\nObjective Content\\ndummylink\\nProgress Note\\nDuration: 60 minutes\\nService Code: 90837\\nThe sessiont took place face to face in the Minot office. The client's spouse was present upon request.\\nInterventions Used\\nThe following interventions were used: Cognitive Reframing, Exploration of Emotions, Exploration of Relationship Patterns, Supportive\\nReflection, and Psycho-Education.\\nTreatment Plan Progress\\nObjectives\\n1. identify problems and one's own role in the relationship\\nProgress: Progressing\\n2. increase frequency of direct expression of honest feelings\\nProgress: Progressing\\n3. learn and implement problem solving and conflict resolution skills\\nProgress: No Progress\\nAssessment / Additional Notes\\nThe client discussed the current impact of her spouse's diagnosis and provided history to her satisfaction in the relationship prior to this\\nyear. The client shared how she utilizes supports during difficult times and identified where anxiety has been recently present. The client\\ncompleted the relationship attachment model.\\nPlan\\nThe client was emailed a handout on control and given a recommendation for the Paired app. She will follow-up in two weeks.\\nRecommendation: Continue current therapeutic focus\\nPrescribed Frequency of Treatment: Weekly\\ndummylink\\nProgress Note\\nDuration: 60 minutes\\nService Code: 90837\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "soap_text_1 = load_pdf(\"soap_note_1.pdf\")\n",
        "deidentify_note_1 = deidentify_and_strip(soap_text_1)\n",
        "\n",
        "deidentify_note_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "cpt_prediction_prompt = \"\"\"You are a medical coding assistant. Your task is to assign the correct CPT code(s) for the clinical note.\n",
        "\n",
        "Rules:\n",
        "- Only choose from the Allowed CPT list provided.  \n",
        "- Base your selection strictly on the documented services performed, not on assumptions.  \n",
        "- If multiple CPT codes are supported by the documentation, return them all.  \n",
        "- If two codes are mutually exclusive, select the one most consistent with time/duration or note details.  \n",
        "- Do not invent codes not in the Allowed CPTs list.  \n",
        "\n",
        "\n",
        "Allowed CPTs:\n",
        "- 90791: Psychiatric diagnostic evaluation\n",
        "- 90832: Psychotherapy, 30 minutes with patient\n",
        "- 90837: Psychotherapy, 60 minutes with patient\n",
        "- H0004: Behavioral health counseling and therapy\n",
        "- 96130: Psychological testing evaluation services, first hour\n",
        "- 96131: Psychological testing evaluation services, each additional hour\n",
        "\n",
        "Examples:\n",
        "Note: \"Patient presented for initial psychiatric diagnostic interview...\" → CPT: 90791\n",
        "Note: \"Session lasted 60 minutes, focused on psychotherapy...\" → CPT: 90837\n",
        "Note: \"Behavioral therapy session lasted 15 minutes...\" → CPT: H0004\n",
        "\n",
        "Now classify the following clinical note and return the result in the specified JSON format:\n",
        "{soap_note}\n",
        "\n",
        "Return the result in this JSON format:\n",
        "{{\n",
        "  \"CPT\": [ \"code1\", \"code2\" ]\n",
        "}}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rf4YLrkfYxaq"
      },
      "outputs": [],
      "source": [
        "class CPT_Output(BaseModel):\n",
        "    CPT: List[Annotated[str, Field(min_length=5, max_length=5, description=\"CPT code descrbing the chart note\")]]\n",
        "\n",
        "structured_llm = llm.with_structured_output(CPT_Output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BAHyR6MdabXq"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"soap_note\"],\n",
        "    template=cpt_prediction_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "QUpNgE_DXVi7",
        "outputId": "aa73bf0b-30f4-451d-a66b-9367a8fa9efa"
      },
      "outputs": [],
      "source": [
        "deidentify_note_2 = deidentify_and_strip(load_pdf(\"soap_note_2.pdf\"))\n",
        "deidentify_note_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufQ6MGBOWsba",
        "outputId": "d8bd90ba-2747-4e2e-db73-2b7ade67e2d0"
      },
      "outputs": [],
      "source": [
        "soap_note_prompt = prompt.format(soap_note=deidentify_note_2)\n",
        "\n",
        "response = structured_llm.invoke(soap_note_prompt)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLo4qEvbbCTZ"
      },
      "outputs": [],
      "source": [
        "def predict_cpt_code(soap_note: str):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"soap_note\"],\n",
        "        template=cpt_prediction_prompt\n",
        "    )\n",
        "\n",
        "    soap_note_prompt = prompt.format(soap_note=soap_note)\n",
        "\n",
        "    response = structured_llm.invoke(soap_note_prompt)\n",
        "\n",
        "    return response.CPT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "G34WSV9zmjW1",
        "outputId": "cf9646c5-0869-42b2-b98c-2dcf771bb06c"
      },
      "outputs": [],
      "source": [
        "cpt_icd_mapping_df = pd.read_excel(\"Expanded_CPT_to_ICD_mapping.xlsx\")\n",
        "cpt_icd_mapping_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-9X8UoMoJs2"
      },
      "outputs": [],
      "source": [
        "def get_cpt_mapping(df):\n",
        "  cpt_mapping = {}\n",
        "\n",
        "  for _, row in cpt_icd_mapping_df.iterrows():\n",
        "    cpt = str(row[\"CPT\"]).strip()\n",
        "    cpt_desc = str(row[\"CPT Description\"]).strip()\n",
        "    icd = str(row[\"ICD-10 Code\"]).strip()\n",
        "    icd_desc = str(row[\"ICD-10 Description\"]).strip()\n",
        "\n",
        "    if cpt not in cpt_mapping:\n",
        "      cpt_mapping[cpt] = {\n",
        "          \"description\": cpt_desc,\n",
        "          \"applicable_icds\": []\n",
        "      }\n",
        "\n",
        "    cpt_mapping[cpt][\"applicable_icds\"].append({\n",
        "        icd: icd_desc,\n",
        "    })\n",
        "\n",
        "  return cpt_mapping\n",
        "\n",
        "cpt_mapping = get_cpt_mapping(cpt_icd_mapping_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djmbnD6spznX"
      },
      "outputs": [],
      "source": [
        "def get_icd_candidates(predicted_cpt_codes: list[str]) -> list[dict]:\n",
        "    \"\"\"Return ICD candidates as list of dicts with consistent keys.\"\"\"\n",
        "    icd_candidates = []\n",
        "    for cpt in predicted_cpt_codes:\n",
        "        if cpt in cpt_mapping:\n",
        "            for icd_entry in cpt_mapping[cpt][\"applicable_icds\"]:\n",
        "                for icd, desc in icd_entry.items():\n",
        "                    icd_candidates.append({\n",
        "                        \"icd\": icd,\n",
        "                        \"description\": desc\n",
        "                    })\n",
        "    return icd_candidates\n",
        "\n",
        "\n",
        "\n",
        "icd_candidadtes = get_icd_candidates([\"90837\", \"90832\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TuVnfslsKgm",
        "outputId": "e59d12a8-dd71-4d63-982a-1d88456b7afc"
      },
      "outputs": [],
      "source": [
        "icd_candidadtes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c3DT8JUukFV"
      },
      "outputs": [],
      "source": [
        "embedder = SentenceTransformer(\"abhinand/MedEmbed-large-v0.1\")\n",
        "\n",
        "def embed_texts(texts: List[str]) -> np.ndarray:\n",
        "    \"\"\"Returns L2-normalized embeddings (np.ndarray) for stable cosine sim.\"\"\"\n",
        "    embs = embedder.encode(\n",
        "        texts,\n",
        "        convert_to_numpy=True,\n",
        "        batch_size=32,\n",
        "        normalize_embeddings=True,\n",
        "        show_progress_bar=False\n",
        "    )\n",
        "    return embs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_icd_embedding_store(mapping_df, embed_fn):\n",
        "    \"\"\"\n",
        "    Precompute embeddings for ICD codes/descriptions.\n",
        "    Returns: dict[str, np.ndarray]\n",
        "    \"\"\"\n",
        "    icd_store = {}\n",
        "    for _, row in mapping_df.iterrows():\n",
        "        key = f\"{row['ICD-10 Code']}: {row['ICD-10 Description']}\"\n",
        "        if key not in icd_store:\n",
        "            icd_store[key] = embed_fn([key])[0]\n",
        "    return icd_store\n",
        "\n",
        "# Build globally (only once, e.g. app startup)\n",
        "ICD_STORE = build_icd_embedding_store(cpt_icd_mapping_df, embed_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SRZ0Ozbv27F"
      },
      "outputs": [],
      "source": [
        "def rerank_icd_candidates(note_text: str,\n",
        "                          icd_candidates: List[Dict[str, str]],\n",
        "                          top_k: int = 5,\n",
        "                          rerank_with_cross_encoder: bool = True) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Re-rank ICD candidates:\n",
        "      1. Fast filter with embeddings (MedEmbed bi-encoder + ICD_STORE lookup).\n",
        "      2. Optional cross-encoder rerank for top-K.\n",
        "    \"\"\"\n",
        "    cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "\n",
        "    if not icd_candidates:\n",
        "        return []\n",
        "\n",
        "    # Normalize ICD candidates\n",
        "    normalized_icds = []\n",
        "    for c in icd_candidates:\n",
        "        if \"icd\" in c and \"description\" in c:\n",
        "            normalized_icds.append({\"icd\": c[\"icd\"], \"description\": c[\"description\"]})\n",
        "        else:\n",
        "            icd, desc = list(c.items())[0]\n",
        "            normalized_icds.append({\"icd\": icd, \"description\": desc})\n",
        "\n",
        "    # Step 1: Bi-encoder embedding filter (lookup instead of recompute)\n",
        "    note_emb = embed_texts([note_text])[0]\n",
        "    icd_texts = [f'{c[\"icd\"]}: {c[\"description\"]}' for c in normalized_icds]\n",
        "    icd_embs = np.array([ICD_STORE[txt] for txt in icd_texts])  # lookup, no re-embed\n",
        "\n",
        "    sims = note_emb @ icd_embs.T\n",
        "    idxs = np.argsort(-sims)[: min(top_k * 3, len(normalized_icds))]\n",
        "\n",
        "    preselected = [\n",
        "        {\n",
        "            \"icd\": normalized_icds[i][\"icd\"],\n",
        "            \"description\": normalized_icds[i][\"description\"],\n",
        "            \"score\": float(sims[i]),\n",
        "        }\n",
        "        for i in idxs\n",
        "    ]\n",
        "\n",
        "    # Step 2: Cross-encoder rerank\n",
        "    if rerank_with_cross_encoder and preselected:\n",
        "        pairs = [(note_text, f\"{p['icd']}: {p['description']}\") for p in preselected]\n",
        "        cross_scores = cross_encoder.predict(pairs)\n",
        "\n",
        "        for p, cs in zip(preselected, cross_scores):\n",
        "            p[\"cross_score\"] = float(cs)\n",
        "\n",
        "        preselected = sorted(preselected, key=lambda x: -x[\"cross_score\"])\n",
        "\n",
        "    # Step 3: Deduplicate by ICD\n",
        "    unique_ranked = {}\n",
        "    for r in preselected[:top_k]:\n",
        "        icd = r[\"icd\"]\n",
        "        if icd not in unique_ranked or r.get(\"cross_score\", r[\"score\"]) > unique_ranked[icd].get(\"cross_score\", r[\"score\"]):\n",
        "            unique_ranked[icd] = r\n",
        "\n",
        "    return sorted(unique_ranked.values(),\n",
        "                  key=lambda x: -(x.get(\"cross_score\", x[\"score\"])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaOUr_q0wF71",
        "outputId": "9f991bc8-0c2a-4689-8222-c78e36eaa40e"
      },
      "outputs": [],
      "source": [
        "ranked = rerank_icd_candidates(deidentify_note_1, icd_candidadtes)\n",
        "\n",
        "ranked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI9nwDGIwQRF"
      },
      "outputs": [],
      "source": [
        "ranked_2 = rerank_icd_candidates(deidentify_note_2, get_icd_candidates([\"90791\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0uKYPPgHwMs",
        "outputId": "f6607e0e-0acd-402b-f5f1-454a1fc0afac"
      },
      "outputs": [],
      "source": [
        "ranked_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jPQiNS2zxIX"
      },
      "outputs": [],
      "source": [
        "class ICD_Output(BaseModel):\n",
        "    ICD10: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Final ICD-10 codes selected from the allowed list; return 1-4 most relevant.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YoFw9vH3cR1"
      },
      "outputs": [],
      "source": [
        "# Wrap your existing llm for structured output\n",
        "icd_structured_llm = llm.with_structured_output(ICD_Output)\n",
        "\n",
        "icd_selection_prompt = PromptTemplate(\n",
        "    input_variables=[\"note\", \"cpts\", \"allowed_icds\"],\n",
        "    template=(\n",
        "        \"You are a medical coding assistant. Choose the most appropriate ICD-10 codes \"\n",
        "        \"ONLY from the allowed list below, based on the clinical note and CPT context. \"\n",
        "        \"Prefer diagnoses that are explicitly supported by the note. Do not guess.\\n\\n\"\n",
        "        \"Clinical note:\\n{note}\\n\\n\"\n",
        "        \"CPT context (predicted): {cpts}\\n\\n\"\n",
        "        \"Allowed ICD-10 candidates (code — description):\\n{allowed_icds}\\n\\n\"\n",
        "        \"Return JSON matching this schema:\\n\"\n",
        "        \"{{\\\"ICD10\\\": [\\\"code1\\\", \\\"code2\\\"]}}\\n\"\n",
        "        \"Constraints:\\n\"\n",
        "        \"- Pick the fewest codes that fully represent the encounter (typically 1-4).\\n\"\n",
        "        \"- Do not include screening codes unless the note is purely screening.\\n\"\n",
        "        \"- Do not include historical/resolved problems unless clearly treated/assessed today.\\n\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OotH1Dlj3eqV"
      },
      "outputs": [],
      "source": [
        "def select_icds_for_note(note_text: str,\n",
        "                         predicted_cpts: List[str],\n",
        "                         icd_candidates: List[Dict[str, str]],\n",
        "                         top_k: int = 15) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Reranks ICD candidates with embeddings, then asks the LLM to pick final ICDs.\n",
        "    Returns dict with ranked list and final selection.\n",
        "    \"\"\"\n",
        "    # Step 1: re-rank by semantic similarity\n",
        "    ranked = rerank_icd_candidates(note_text, icd_candidates, top_k=top_k)\n",
        "\n",
        "    if not ranked:\n",
        "        return {\"ranked\": [], \"final\": []}\n",
        "\n",
        "    # Prepare allowed list text for the prompt (top-K only)\n",
        "    allowed_lines = [f\"- {r['icd']} — {r['description']} (score: {r['score']:.3f})\" for r in ranked]\n",
        "    allowed_icds_block = \"\\n\".join(allowed_lines)\n",
        "\n",
        "    # Step 2: LLM final selection (structured)\n",
        "    prompt_str = icd_selection_prompt.format(\n",
        "        note=note_text,\n",
        "        cpts=\", \".join(predicted_cpts),\n",
        "        allowed_icds=allowed_icds_block\n",
        "    )\n",
        "    final = icd_structured_llm.invoke(prompt_str)\n",
        "\n",
        "    return {\n",
        "        \"ranked\": ranked,            # list of dicts with score\n",
        "        \"final\": final.ICD10         # list of codes selected by the LLM\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHx2Zw273ng0"
      },
      "outputs": [],
      "source": [
        "final_selection = select_icds_for_note(deidentify_note_1, [\"90837\"], icd_candidadtes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqGFuZzB4BBF",
        "outputId": "8526428c-a85f-4596-e3c8-19e1a1e3bab2"
      },
      "outputs": [],
      "source": [
        "final_selection[\"final\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFrXx7QW5NdF"
      },
      "outputs": [],
      "source": [
        "def generate_coding_from_note(file_path: str,\n",
        "                  top_k: int = 5) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Full CPT -> ICD pipeline.\n",
        "    Input: PDF clinical note path\n",
        "    Output: dict with CPTs, ranked ICD candidates, and final ICDs\n",
        "    \"\"\"\n",
        "    # Step 1: Load and clean note\n",
        "    text_content = load_pdf(file_path)\n",
        "    deidentified_text = deidentify_and_strip(text_content)\n",
        "\n",
        "    # Step 2: Predict CPT(s)\n",
        "    predicted_cpts = predict_cpt_code(deidentified_text)\n",
        "\n",
        "\n",
        "    # Step 4: Collect ICD candidates\n",
        "    icd_candidates = get_icd_candidates(predicted_cpts)\n",
        "\n",
        "    # Step 5: Re-rank candidates and finalize with LLM\n",
        "    final_selection = select_icds_for_note(\n",
        "        note_text=deidentified_text,\n",
        "        predicted_cpts=predicted_cpts,\n",
        "        icd_candidates=icd_candidates,\n",
        "        top_k=top_k\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"cpts\": predicted_cpts,\n",
        "        \"ranked_icds\": final_selection[\"ranked\"],\n",
        "        \"final_icds\": final_selection[\"final\"]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR4UbvjS5u3F",
        "outputId": "dd92e2bf-8cba-45ca-9672-3288178a0c7e"
      },
      "outputs": [],
      "source": [
        "files = [\"soap_note_1.pdf\", \"soap_note_2.pdf\", \"soap_note_3.pdf\"]\n",
        "\n",
        "for file in files:\n",
        "\n",
        "  result = generate_coding_from_note(file, cpt_icd_mapping_df)\n",
        "\n",
        "  print(f\"\\nPredicted CPTs for {file}:\")\n",
        "  for cpt in result[\"cpts\"]:\n",
        "      print(f\" - {cpt}\")\n",
        "\n",
        "  print(f\"\\nFinal ICDs for {file}:\")\n",
        "  for icd in result[\"final_icds\"]:\n",
        "      print(f\" - {icd}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjdpm-Tm9CXV"
      },
      "outputs": [],
      "source": [
        "def unzip_folder(zip_path, extract_to):\n",
        "  os.makedirs(extract_to, exist_ok=True)\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_to)\n",
        "\n",
        "unzip_folder(\"soap_notes_dir.zip\", \"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "for file in tqdm(os.listdir(\"/content/soap_notes_dir\"), desc=\"Processing SOAP Notes\"):\n",
        "  if file.endswith(\".pdf\"):\n",
        "    result = generate_coding_from_note(f\"/content/soap_notes_dir/{file}\", cpt_icd_mapping_df)\n",
        "    predictions.append({\n",
        "        \"file\": file,\n",
        "        \"cpts\": result[\"cpts\"],\n",
        "        \"final_icds\": result[\"final_icds\"]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define headings + regex patterns for flexibility\n",
        "required_sections = {\n",
        "    \"Interventions Used\": r\"\\bInterventions\\s+Used\\b\",\n",
        "    # Match \"Risk Assessment\" OR \"Assessment\" optionally followed by\n",
        "    # words, slashes, or spaces\n",
        "    \"Risk Assessment\": r\"\\b(Risk\\s+Assessment|Assessment(\\s*[/\\-\\w\\s]+)*)\\b\",\n",
        "    \"Current Mental Status\": r\"\\bCurrent\\s+Mental\\s+Status\\b\"\n",
        "}\n",
        "\n",
        "def check_note(note_text: str, filename: str):\n",
        "    missing = []\n",
        "    \n",
        "    for section, pattern in required_sections.items():\n",
        "        if not re.search(pattern, note_text, flags=re.IGNORECASE):\n",
        "            missing.append(section)\n",
        "\n",
        "    if missing:\n",
        "        return {\n",
        "            \"filename\": filename,\n",
        "            \"status\": \"RED\",\n",
        "            \"missing_sections\": missing\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"filename\": filename,\n",
        "            \"status\": \"OK\",\n",
        "            \"missing_sections\": []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flagged_notes = []\n",
        "\n",
        "\n",
        "for file in tqdm(os.listdir(\"flag_red_notes_dir\")):\n",
        "    if file.endswith(\".pdf\"):\n",
        "        with open(f\"flag_red_notes_dir/{file}\", \"r\") as f:\n",
        "            text_content = load_pdf(f\"flag_red_notes_dir/{file}\")\n",
        "            # cleaned_text = deidentify_and_strip(text_content)\n",
        "            \n",
        "            result = check_note(text_content, file)\n",
        "            if result[\"status\"] == \"RED\":\n",
        "                flagged_notes.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flagged_notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flagged_files = [n[\"filename\"] for n in flagged_notes]\n",
        "flagged_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "folder_name = \"flag_red_notes_dir\"\n",
        "\n",
        "for file in tqdm(os.listdir(folder_name), desc=\"Processing SOAP Notes\"):\n",
        "  if file.endswith(\".pdf\") and file not in flagged_files:\n",
        "    result = generate_coding_from_note(f\"{folder_name}/{file}\", cpt_icd_mapping_df)\n",
        "    predictions.append({\n",
        "        \"file\": file,\n",
        "        \"cpts\": result[\"cpts\"],\n",
        "        \"final_icds\": result[\"final_icds\"]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = load_pdf(r\"flag_red_notes_dir\\TN_Note-for-AM-8-20-2025_created-8-27-2025_58397489.pdf\")\n",
        "clean = deidentify_and_strip(text)\n",
        "\n",
        "print(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cpt = predict_cpt_code(clean)\n",
        "cpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf = \"flag_red_notes_dir\\TN_Note-for-IH-8-21-2025_created-8-27-2025_58397573.pdf\"\n",
        "text = load_pdf(pdf)\n",
        "# clean = deidentify_and_strip(text)\n",
        "# cpt = predict_cpt_code(clean)\n",
        "\n",
        "# cpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf = \"flag_red_notes_dir\\TN_Note-for-WK-8-20-2025_created-8-27-2025_58397504.pdf\"\n",
        "text = load_pdf(pdf)\n",
        "# clean = deidentify_and_strip(text)\n",
        "# cpt = predict_cpt_code(clean)\n",
        "\n",
        "# cpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_date(date_str: str) -> str:\n",
        "    \"\"\"\n",
        "    Try to parse date in multiple formats and return as DD-MM-YYYY.\n",
        "    If parsing fails, return original string.\n",
        "    \"\"\"\n",
        "    date_formats = [\n",
        "        \"%m/%d/%Y\", \"%m-%d-%Y\", \"%Y-%m-%d\", \"%d-%m-%Y\", \"%d/%m/%Y\",\n",
        "        \"%B %d, %Y\", \"%b %d, %Y\"  # March 5, 2023 / Mar 5, 2023\n",
        "    ]\n",
        "    for fmt in date_formats:\n",
        "        try:\n",
        "            return datetime.strptime(date_str.strip(), fmt).strftime(\"%d-%m-%Y\")\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return date_str  # fallback if format unknown\n",
        "\n",
        "def split_date_time(datetime_str: str):\n",
        "    \"\"\"\n",
        "    Try to split date and time. Returns (date, time) where time may be ''.\n",
        "    \"\"\"\n",
        "    # Common pattern: \"MM/DD/YYYY HH:MM AM/PM\" or \"YYYY-MM-DD HH:MM\"\n",
        "    parts = datetime_str.strip().split(\" \", 1)\n",
        "    if len(parts) == 2:\n",
        "        return format_date(parts[0]), parts[1].strip()\n",
        "    else:\n",
        "        return format_date(datetime_str.strip()), \"\"\n",
        "\n",
        "def get_phi(note_text: str) -> dict:\n",
        "    details = {}\n",
        "\n",
        "    # Clinician\n",
        "    clinician_match = re.search(r\"Clinician:\\s*(.+)\", note_text)\n",
        "    if clinician_match:\n",
        "        details[\"Clinician\"] = clinician_match.group(1).strip()\n",
        "\n",
        "    # Supervisor\n",
        "    supervisor_match = re.search(r\"Supervisor:\\s*(.+)\", note_text)\n",
        "    if supervisor_match:\n",
        "        details[\"Supervisor\"] = supervisor_match.group(1).strip()\n",
        "\n",
        "    # Patient & DOB\n",
        "    patient_match = re.search(r\"Patient:\\s*([^,]+),\\s*DOB\\s*([^\\n]+)\", note_text)\n",
        "    if patient_match:\n",
        "        details[\"Patient\"] = patient_match.group(1).strip()\n",
        "        details[\"DOB\"] = format_date(patient_match.group(2).strip())\n",
        "\n",
        "    # Date & Time\n",
        "    datetime_match = re.search(r\"Date and Time:\\s*([^\\n]+)\", note_text)\n",
        "    if datetime_match:\n",
        "        date_str, time_str = split_date_time(datetime_match.group(1))\n",
        "        details[\"Date\"] = date_str\n",
        "        if time_str:\n",
        "            details[\"Time\"] = time_str\n",
        "\n",
        "    # Duration\n",
        "    duration_match = re.search(r\"Duration:\\s*([^\\n]+)\", note_text)\n",
        "    if duration_match:\n",
        "        details[\"Duration\"] = duration_match.group(1).strip()\n",
        "\n",
        "    # Service Code\n",
        "    service_code_match = re.search(r\"Service Code:\\s*([A-Z0-9]+)\", note_text)\n",
        "    if service_code_match:\n",
        "        details[\"Service Code\"] = service_code_match.group(1).strip()\n",
        "\n",
        "    # ---------------------------\n",
        "    # Diagnosis (ICD-10 extraction)\n",
        "    # ---------------------------\n",
        "    diagnosis_section = None\n",
        "    section_start = re.search(r\"(Diagnosis|Diagnoses|Dx)[:\\-]?\", note_text, re.IGNORECASE)\n",
        "    if section_start:\n",
        "        diagnosis_section = note_text[section_start.start():]\n",
        "\n",
        "        stop_match = re.search(r\"(Plan|Treatment|Intervention|Procedure|Assessment)[:\\-]?\", diagnosis_section, re.IGNORECASE)\n",
        "        if stop_match:\n",
        "            diagnosis_section = diagnosis_section[:stop_match.start()]\n",
        "\n",
        "    if diagnosis_section:\n",
        "        icd_pattern = r\"\\b[A-TV-Z]\\d{2}(?:\\.\\d{1,2})?\\b\"\n",
        "        diagnosis_codes = list(set(re.findall(icd_pattern, diagnosis_section)))\n",
        "        if diagnosis_codes:\n",
        "            details[\"Diagnosis Codes\"] = diagnosis_codes\n",
        "\n",
        "    return details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phi = get_phi(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "phi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
